{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#pre-process text \n",
    "import nltk\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "#transform data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "#model libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#import log function \n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spooky Author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Corpus of Spooky Authors dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train data to Pandas dataframe\n",
    "train_df = pd.read_csv('train.csv')\n",
    "#load test data\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic EDA on train and test data using Pandas and Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ...\n",
       "2  id00134  And when they had broken down the frail door t...\n",
       "3  id27757  While I was thinking how I should possibly man...\n",
       "4  id04081  I am not sure to what limit his knowledge may ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19579</td>\n",
       "      <td>19579</td>\n",
       "      <td>19579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>19579</td>\n",
       "      <td>19579</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>id07525</td>\n",
       "      <td>Pestilence then made a pause in her death deal...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text author\n",
       "count     19579                                              19579  19579\n",
       "unique    19579                                              19579      3\n",
       "top     id07525  Pestilence then made a pause in her death deal...    EAP\n",
       "freq          1                                                  1   7900"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8392</td>\n",
       "      <td>8392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>8392</td>\n",
       "      <td>8392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>id26558</td>\n",
       "      <td>I burned to say if but one word, by way of tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "count      8392                                               8392\n",
       "unique     8392                                               8392\n",
       "top     id26558  I burned to say if but one word, by way of tri...\n",
       "freq          1                                                  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19579 entries, 0 to 19578\n",
      "Data columns (total 3 columns):\n",
      "id        19579 non-null object\n",
      "text      19579 non-null object\n",
      "author    19579 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 459.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8392 entries, 0 to 8391\n",
      "Data columns (total 2 columns):\n",
      "id      8392 non-null object\n",
      "text    8392 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 131.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1V4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6ecd5f828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot('author',data = train_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes seem balanced across three authors, which informs my approach in splitting the training data for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encode Authors\n",
    "\n",
    "Here, I am changing the target variable from acronyms of authors to numbers. Since three variables exist, variables are given numbers 0, 1, and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import label encoder to transform target variables\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train_df['author_numerical'] = le.fit_transform(train_df['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>author_numerical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "   author_numerical  \n",
       "0                 0  \n",
       "1                 1  \n",
       "2                 0  \n",
       "3                 2  \n",
       "4                 1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and valid sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test-split the training set into training set and validation set to train our model which will then be used on the actual test data test_df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = train_df['author_numerical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the training data with the label-encoded column as the target \n",
    "x_train, X_valid, y_train, Y_valid = train_test_split(train_df.text.values, Y, \n",
    "                                                      random_state=42,\n",
    "                                                      test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process and Rescale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard structure of the text using bag-of-words representation to see how often each word appears in each text in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process text using stemmer to regularize text\n",
    "def stem_tokens(tokens, stemmer): \n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "#turn texts to tokens \n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [i for i in tokens if len(i) > 2] #gets rid of 1-2 character tokens\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stop_words = 'engish' uses the built-in list ENGLISH_STOP_WORDS\n",
    "#discarding all words that show up less than twice (min_df = 2)\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=tokenize, min_df = 2, stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function tokenize at 0x7ff6d3e46840>, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the training set before transforming data\n",
    "tfidf_vectorizer.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transform train set and validation set into tfidf vectors\n",
    "x_train_tfidf = tfidf_vectorizer.transform(x_train) \n",
    "X_valid_tfidf = tfidf_vectorizer.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1958, 9726) (17621, 9726)\n"
     ]
    }
   ],
   "source": [
    "print(X_valid_tfidf.shape, x_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit to model\n",
    "\n",
    "I chose Logistic Regression, Multinomial NB, and Random Forest. Before applying each model I used GridSearch CV to determine optimal hyperparameters to train my models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_params = {\n",
    "    'C':np.logspace(-3,3,7),\n",
    "    'penalty':['l2','l1']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrgs = GridSearchCV(LogisticRegression(),\n",
    "                    param_grid=lr_params,\n",
    "                    cv=StratifiedShuffleSplit(n_splits=5, test_size=.2, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=42, test_size=0.2,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([  1.00000e-03,   1.00000e-02,   1.00000e-01,   1.00000e+00,\n",
       "         1.00000e+01,   1.00000e+02,   1.00000e+03]), 'penalty': ['l2', 'l1']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrgs.fit(x_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81225531914893612"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrgs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10.0, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Logistic Regression on TFIDF using best params\n",
    "clf = LogisticRegression(C=10.0, penalty='l2')\n",
    "clf.fit(x_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50293098006304271"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = clf.predict_proba(X_valid_tfidf)\n",
    "\n",
    "log_loss(Y_valid, probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'alpha':[0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "grid_nb = GridSearchCV(MultinomialNB(), \n",
    "                       param_grid=params, \n",
    "                       cv=StratifiedShuffleSplit(n_splits=5, test_size=.2, random_state=42))\n",
    "grid_nb.fit(x_train_tfidf, y_train)\n",
    "grid_nb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the best params\n",
    "nb = MultinomialNB(alpha=0.1)\n",
    "# fit the model \n",
    "nb.fit(x_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47651461290289437"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = nb.predict_proba(X_valid_tfidf)\n",
    "\n",
    "log_loss(Y_valid, probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search on random forest took too long, will try one version\n",
    "grid_forest = RandomForestClassifier(n_estimators=100)\n",
    "grid_forest.fit(x_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73472052096266138"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = grid_forest.predict_proba(X_valid_tfidf)\n",
    "\n",
    "log_loss(Y_valid, probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform test data using the model that had the best score: MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = test_df.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf = tfidf_vectorizer.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = nb.predict_proba(test_tfidf)\n",
    "\n",
    "preds = nb.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8392"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8392"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(probas, index=test_df['id'], columns=['EAP', 'HPL', 'MWS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id02310</th>\n",
       "      <td>0.055245</td>\n",
       "      <td>0.024885</td>\n",
       "      <td>0.919870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24541</th>\n",
       "      <td>0.859257</td>\n",
       "      <td>0.081845</td>\n",
       "      <td>0.058899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00134</th>\n",
       "      <td>0.291505</td>\n",
       "      <td>0.656829</td>\n",
       "      <td>0.051665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27757</th>\n",
       "      <td>0.479138</td>\n",
       "      <td>0.516269</td>\n",
       "      <td>0.004593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04081</th>\n",
       "      <td>0.778883</td>\n",
       "      <td>0.127610</td>\n",
       "      <td>0.093508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              EAP       HPL       MWS\n",
       "id                                   \n",
       "id02310  0.055245  0.024885  0.919870\n",
       "id24541  0.859257  0.081845  0.058899\n",
       "id00134  0.291505  0.656829  0.051665\n",
       "id27757  0.479138  0.516269  0.004593\n",
       "id04081  0.778883  0.127610  0.093508"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
